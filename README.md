# Weigh LifeStyle ‚Äî Pr√©diction du poids (LightGBM, RandomForest & Ridge)

Projet de r√©gression qui relie hygi√®ne de vie et poids corporel. Les notebooks fournissent l'EDA initiale tandis que la pipeline automatis√©e g√®re nettoyage, splits, tuning Optuna, entra√Ænement et √©valuation (m√©triques + SHAP). Une baseline lin√©aire Ridge est incluse pour comparer aux mod√®les plus complexes.

## Objectifs
- Obtenir un pipeline reproductible sans fuite de donn√©es du test.
- Pinner l'entra√Ænement LightGBM avec un jeu d'hyperparam√®tres consign√©.
- Conserver tous les artefacts (donn√©es d√©riv√©es, mod√®les, graphiques) dans le d√©p√¥t pour audit.

## Configuration de l‚Äôenvironnement
Pr√©requis¬†: Python 3.10+.

```bash
python -m venv .venv
source .venv/bin/activate  # Windows¬†: .venv\Scripts\activate
pip install -r requirements.txt
# D√©pendances suppl√©mentaires pour les tests et linters
pip install -r requirements-dev.txt
```

> üí° Les scripts CLI sont ex√©cutables sans installation du paquet gr√¢ce √† l‚Äôinjection du `PROJECT_ROOT` dans `sys.path`. Aucune variable d‚Äôenvironnement sp√©cifique n‚Äôest n√©cessaire.

## Conventions & respect des instructions
- Les r√®gles globales (PEP¬†8, KISS, DRY, type hints‚Ä¶) sont d√©crites dans `AGENTS.md` √† la racine. Toute modification de code ou de documentation doit en tenir compte.
- Les chemins sont d√©riv√©s de `src/constants.py`¬†: utiliser `PROJECT_ROOT`, `DATA_DIR`, `RESULTS_DIR`, etc., au lieu de concat√©nations manuelles.
- Pour la journalisation, remplacer tout `print` par `get_logger(__name__)` depuis `src.utils`.

## Flux de travail recommand√©
### 1. Pr√©parer les donn√©es sources
- D√©poser le CSV brut dans `data/dataset.csv`.
- (Optionnel) Mettre √† jour les notebooks si de nouvelles colonnes apparaissent.

### 2. Ex√©cuter les notebooks d‚ÄôEDA
- `notebooks/analyse_univariee.ipynb`¬†: distribs, valeurs extr√™mes, export `data/dataset_cleaned.csv`.
- `notebooks/analyse_bivariee_multivariee.ipynb`¬†: corr√©lations, scatterplots, profils cat√©goriels.
- Sauvegarder les visualisations dans `plots/` pour conserver l‚Äôhistorique.

### 3. Lancer les scripts CLI
| √âtape | Commande | Entr√©es | Sorties cl√©s |
|-------|----------|---------|--------------|
| Nettoyage | `python -m src.data_cleaning.main` | `data/dataset_cleaned.csv` | `data/dataset_cleaned_final.(csv|parquet)`, plot de distribution |
| Pr√©paration | `python -m src.data_preparation.main` | Fichier nettoy√© final | Splits encod√©s + mappings OneHotEncoder |
| Hyperparam√®tres | `python -m src.hyperparameters_optimization.main --models both` | Splits encod√©s | `results/best_lightgbm_params.json`, `results/best_random_forest_params.json` |
| Feature importance | `python -m src.feature_engineering.main` | Splits encod√©s | JSON + graphique de permutation |
| Entra√Ænement (LGBM/RF) | `python -m src.training.main --models both` | Splits encod√©s + JSON d‚Äôhyperparam√®tres | `results/models/*.joblib` + m√©triques validation |
| √âvaluation (LGBM/RF/Ridge) | `python -m src.eval.main --models all` | Splits encod√©s + mod√®les | `results/eval/*.json`, rapports SHAP |
| Baseline Ridge ‚Äî Optuna | `python -m src.baseline.main --optimize` | Splits encod√©s | `results/best_ridge_params.json` (CV 5-fold) |
| Baseline Ridge ‚Äî Entra√Ænement | `python -m src.baseline.main --train` | Splits encod√©s + JSON Ridge | `results/models/ridge.joblib` + scaler no-op |
| End-to-end | `python -m src.main_global` | Orchestrateur | Encha√Ænement complet |

Les chemins par d√©faut des arguments CLI proviennent tous de `src/constants.py`. Les artefacts √©crits lors du run sont automatiquement convertis en chemins relatifs via `src.utils.to_project_relative_path`, ce qui facilite le versioning.

### 4. Tests et v√©rifications
- `pytest`¬†: ex√©cute les tests unitaires et d‚Äôint√©gration.
- `pytest -k e2e`¬†: rejoue le test end-to-end √† partir des fixtures mock√©es.
- `python -m src.main_global`¬†: smoke test manuel sur les fichiers pr√©sents dans `data/`.

### 5. Gestion des r√©sultats
- Mod√®les sauvegard√©s dans `results/models/` (LightGBM et RandomForest).
- M√©triques finales dans `results/eval/` (JSON) et SHAP dans `plots/shape/`.
- Les mappings d‚Äôencodage et splits restent dans `data/` pour rejouer la pipeline.

Chaque √©tape est d√©taill√©e dans `documentation/methodologie.txt`.

## Gestion centralis√©e des chemins
- `src/constants.py` d√©finit les r√©pertoires (`DATA_DIR`, `RESULTS_DIR`, `PLOTS_DIR`, etc.) et les noms de fichiers par d√©faut.
- `src.utils.to_project_relative_path` garantit que les chemins stock√©s dans les JSON sont relatifs (ex. `results/models/lightgbm.joblib`).
- Les scripts v√©rifient/cr√©ent les dossiers parents n√©cessaires avant d‚Äô√©crire un fichier.

## Structure du d√©p√¥t

```
data/                         # Donn√©es brutes, interm√©diaires et finales
notebooks/                    # EDA univari√©e et bivari√©e
plots/                        # Visualisations (distributions, corr√©lations, SHAP, permutation)
results/                      # Hyperparam√®tres, m√©triques et mod√®les sauvegard√©s
src/
  data_cleaning/              # Normalisation colonnes + binarisation exercise
  data_preparation/           # Shuffle, split train/test, encodage OneHotEncoder
  feature_engineering/        # Importance par permutation
  hyperparameters_optimization/ # Optuna (LightGBM & RandomForest)
  training/                   # Entra√Ænement LightGBM + RandomForest
  eval/                       # √âvaluation test + SHAP
  utils.py                    # Fonctions partag√©es (chargement, encodage, validations)
main_global.py                # Orchestrateur end-to-end
documentation/methodologie.txt # M√©thodologie d√©taill√©e
documentation/Lightgbm_results.md # Synth√®se JSON LightGBM pr√™te √† lire
documentation/rf_results.md      # Synth√®se JSON RandomForest pr√™te √† lire

```

Les d√©pendances couvrent LightGBM, Optuna, SHAP, Matplotlib/Seaborn (EDA & plots) et scikit-learn. Pour l‚Äôanalyse statique, `requirements-dev.txt` fournit `black`, `ruff` et `pytest`.

Tuning Optuna:
- LightGBM/RandomForest: split train/val fixe (pas de CV) pour limiter le temps de calcul.
- Ridge: validation crois√©e K-fold (par d√©faut 5), avec pr√©traitements (encodage/standardisation) refaits strictement √† l‚Äôint√©rieur de chaque fold (pas de fuite).

## Journalisation
- `src.utils.get_logger` configure un logger unique (format homog√®ne, sortie standard) partag√© par tous les modules CLI.
- Remplacer tout `print` applicatif par `LOGGER = get_logger(__name__)` puis `LOGGER.info(...)`/`LOGGER.warning(...)` selon le niveau souhait√©.
- Les logs d'erreur utilisent `LOGGER.error` afin d'√™tre captur√©s par les pipelines externes tout en conservant la trace compl√®te.
- Aucun test n'instancie ce logger pour √©viter les d√©pendances implicites ; seules les commandes utilisateur y font appel.

## R√©sultats cl√©s

### M√©triques sur le jeu de test
- **LightGBM** :
  - MSE : 1.34 | RMSE : 1.16 | MAE : 0.74 | R¬≤ : 0.9970
  - Hyperparam√®tres optimaux dans `results/best_lightgbm_params.json`
  - Documentation d√©taill√©e : `documentation/Lightgbm_results.md`
  
- **Random Forest** :
  - MSE : 0.67 | RMSE : 0.82 | MAE : 0.52 | R¬≤ : 0.9985
  - Hyperparam√®tres optimaux dans `results/best_random_forest_params.json`
  - Documentation d√©taill√©e : `documentation/rf_results.md`

- **Ridge (baseline lin√©aire)** :
  - √âvalu√©e via `python -m src.eval.main --models ridge` (ou `all`).
  - JSON: `results/eval/ridge_test_metrics.json` (contient MAE/MSE/RMSE/R¬≤, variances, etc.).
  - Mod√®le s√©rialis√©: `results/models/ridge.joblib` (Pipeline sklearn int√©grant encodage + standardisation + Ridge).

- **Features les plus importantes** (SHAP) : `water-intake-(liters)`, `cholesterol-mg`, `age`, `session-duration-(hours)`.
- **Visualisations** : m√©triques + SHAP enregistr√©s sous `results/eval/` et `plots/shape/`.

## Changements r√©cents
- Normalisation des chemins via `src.constants` et `to_project_relative_path` pour √©viter tout chemin absolu dans les artefacts.
- Ajout d‚Äôoptions `--models` sur les CLI `training` et `eval` afin de s√©lectionner LightGBM, RandomForest ou les deux.
- Harmonisation des tests d‚Äôint√©gration (`pytest`) autour de jeux de donn√©es synth√©tiques.
- Baseline Ridge migr√©e en Pipeline sklearn (encodage OneHot + StandardScaler + Ridge), tuning Optuna avec CV K-fold (5) sans fuite (pr√©traitements refaits par fold). L‚Äôoutil d‚Äô√©valuation supporte d√©sormais Ridge.

## Reproductibilit√©
- Seeds centralis√©s dans `src/constants.py` (`DEFAULT_RANDOM_STATE`).
- Encodages cat√©goriels persist√©s (`data/encoders_mappings.*`).
- Splits et artefacts √©crits dans des chemins stables pour faciliter la r√©-ex√©cution.
- Les tests unitaires (`pytest`) s'appuient sur des donn√©es simul√©es (mock) pour ne pas d√©pendre des CSV r√©els.

## Assistance LLM
Ce projet a √©t√© d√©velopp√© avec l'assistance d'un LLM **uniquement pour l'√©criture des lignes de code**. La m√©thodologie, l'architecture et les d√©cisions techniques ont √©t√© con√ßues par l'auteur. Pour plus de d√©tails sur l'utilisation de l'IA dans ce projet, consultez `documentation/LLM_assistance_methodologie.txt`.

## Pistes d'am√©lioration
- √âtendre le tuning Optuna √† une validation crois√©e pour les sc√©narios serveur.
- Ajouter un rapport de monitoring (MLflow/Weights & Biases) pour suivre les runs.
- Exp√©rimenter d'autres mod√®les gradient boosting (CatBoost, XGBoost) dans la m√™me infrastructure.

## Licence
√Ä d√©finir par le propri√©taire du d√©p√¥t.
